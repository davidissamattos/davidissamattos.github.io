<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on David&#39;s public blog</title>
    <link>http://localhost:1313/post/</link>
    <description>Recent content in Posts on David&#39;s public blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Tue, 03 May 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Causal graphs in automotive experimentation</title>
      <link>http://localhost:1313/post/2022/causal-dag/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2022/causal-dag/</guid>
      <description>&lt;p&gt;Today, we received the news that our (very short) paper on the use of Causal DAGs for designing experiments was accepted to be presented in EASE 2022.&lt;/p&gt;&#xA;&lt;p&gt;The paper argues that we should design our experiments with the use of DAGs. That improves communication between stakeholders, allows us to verify our domain knowledge with causal discovery checks and even calculate directs and indirect effects that are not possible with just the experiment result (which only gives the total effect).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Updates</title>
      <link>http://localhost:1313/post/2021/updates_nov/</link>
      <pubDate>Mon, 29 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2021/updates_nov/</guid>
      <description>&lt;p&gt;I hope now that I have a bit more time, I can write more here.&lt;/p&gt;&#xA;&lt;p&gt;In the last few months, I concluded my Ph.D.! The dissertation can be found &lt;a href=&#34;https://research.chalmers.se/publication/524749&#34;&gt;here&lt;/a&gt; and it is a wrap-up of these last 5 years of publications.&lt;/p&gt;&#xA;&lt;p&gt;At the same time, I started my new role as an A/B testing method expert at Volvo Cars, where we will start running A/B testing to continuously improve the software present in our vehicles!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Plot Panels in R (from brms models)</title>
      <link>http://localhost:1313/post/2021/plot-panels-in-r/</link>
      <pubDate>Thu, 20 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2021/plot-panels-in-r/</guid>
      <description>&lt;p&gt;This week I had to make a panel with results from 5 different &lt;a href=&#34;http://paul-buerkner.github.io/brms/&#34;&gt;&lt;code&gt;brms&lt;/code&gt;&lt;/a&gt; models in R. The &lt;code&gt;ggplot2&lt;/code&gt; allows you to do &lt;code&gt;facet_wraps&lt;/code&gt; to create a panel with multiple plots but it also requires that you have a well formated dataframe.&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;brms&lt;/code&gt; provides some functions to create conditional effects plots. The plots are ready and can be easily customized with &lt;code&gt;ggplot2&lt;/code&gt;. While the package offers functions to retrieve the data frame, I did not want to recreate the plots. They were already fine.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Paper accepted at IEEE Transactions on Evolutionary Computation!</title>
      <link>http://localhost:1313/post/2021/statscomp-accepted/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2021/statscomp-accepted/</guid>
      <description>&lt;p&gt;I am happy to announce that our paper &amp;ldquo;Statistical Models for the Analysis of Optimization Algorithms with Benchmark Functions&amp;rdquo; by David Issa Mattos, Jan Bosch and Helena Holmström Olsson has been accepted for publication at the &lt;a href=&#34;https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4235&#34;&gt;IEEE Transactions on Evolutionary Computation&lt;/a&gt; (DOI:10.1109/TEVC.2021.3081167)!&lt;/p&gt;&#xA;&lt;p&gt;The process took roughly 10 months with 3 revisions and has been accepted this week.&lt;/p&gt;&#xA;&lt;p&gt;The abstract follows below and the pre-print can be found at &lt;a href=&#34;https://arxiv.org/pdf/2010.03783.pdf&#34;&gt;https://arxiv.org/pdf/2010.03783.pdf&lt;/a&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Frequentist statistical methods, such as hypothesis testing, are standard practices in studies that provide benchmark comparisons.  Unfortunately, these methods have often been misused, e.g., without testing for their statistical test assumptions or without controlling for family-wise errors in multiple group comparisons, among several other problems. Bayesian Data Analysis (BDA) addresses many of the previously mentioned shortcomings but its use is not widely spread in the analysis of empirical data in the evolutionary computing community. This paper provides three main contributions. First, we motivate the need for utilizing Bayesian data analysis and provide an overview of this topic. Second, we discuss the practical aspects of BDA to ensure that our models are valid and the results are transparent. Finally, we provide five statistical models that can be used to answer multiple research questions. The online appendix provides a step-by-step guide on how to perform the analysis of the models discussed in this paper, including the code for the statistical models, the data transformations, and the discussed tables and figures.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Structuring a Latex project for a paper</title>
      <link>http://localhost:1313/post/2021/project-latex/</link>
      <pubDate>Tue, 11 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2021/project-latex/</guid>
      <description>&lt;p&gt;Over the last five years, I have written papers in different combinations of Word + Mendeley/Zotero, Latex/Overleaf, Google Docs + Zotero, Word Online + Mendeley.&lt;/p&gt;&#xA;&lt;p&gt;Writing papers in Word together with a good reference manager (Zotero/Mendeley) is a smooth experience, given that the journal/conference provides a good template with styles or macros to format. However, a big drawback is when you have your paper rejected or need to place them in another specific format. Then, a lot of your time goes into making your new template work, copy and pasting figures, re-adjusting captions etc.&lt;/p&gt;</description>
    </item>
    <item>
      <title>On the Assessment of Benchmark Suites for Algorithm Comparison</title>
      <link>http://localhost:1313/post/2021/evo-irt-paper/</link>
      <pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2021/evo-irt-paper/</guid>
      <description>&lt;p&gt;Today, we submitted a new paper (On the Assessment of Benchmark Suites for Algorithm Comparison) to the IEEE Transactions on Evolutionary Computing (and of course to Arxiv). In this paper, we challenge the current state-of-the-art suites used for benchmarking in evolutionary computing.&lt;/p&gt;&#xA;&lt;p&gt;Specifically, we utilize a Bayesian Item Response Theory model combined with Fisher Information to analyze how two famous benchmark suites (the BBOB and the PBO) actually perfom in practice in terms of the empirical succcess rate. We found that there is a big mismatch between the difficulty levels of these suites and the state-of-the-art algorithms. This leads to benchmark suites that have low discrimination and that are not good at estimating the ability of algorithms to solve a problem.&lt;/p&gt;</description>
    </item>
    <item>
      <title>bpcs - release v.1.2.0</title>
      <link>http://localhost:1313/post/2021/bpcs-release-1.2.0/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2021/bpcs-release-1.2.0/</guid>
      <description>&lt;p&gt;We have a new release of the bpcs package on Github. This release introduces a few new features, removed dependencies and mostly moved from rstan to cmdstanr.&lt;/p&gt;&#xA;&lt;p&gt;Therefore we require that you have cmdstanr and cmdstan installed and configured prior to use the package. Compilation of the model is done only once by cmdstan outside the R environment&lt;/p&gt;&#xA;&lt;p&gt;See below the release notes:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Moving to cmdstanr instead of rstan.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;This will allow us to fix some bugs and tweaks that were not optimal.&lt;/li&gt;&#xA;&lt;li&gt;Now we can have faster installations and let cmdstan compile the models.&lt;/li&gt;&#xA;&lt;li&gt;There will be some additional time to compile the models for the first time but that is only the first time we use it&lt;/li&gt;&#xA;&lt;li&gt;We can now remove the errors from ubsan-clang in CRAN which apparently is a lot of trial and error to solve and not supporting tools from CRAN for identifying that&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;The interface of the bpcs will remain (practically) the same&lt;/li&gt;&#xA;&lt;li&gt;new function to retrieve the posterior distribution of the parameters &lt;code&gt;get_parameters_posterior&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;alias to retrieve the summary data frame of the parameters &lt;code&gt;get_parameters_df&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Removed dependency on coda&lt;/li&gt;&#xA;&lt;li&gt;Now we can specify the probability mass in the parameters and in summary&lt;/li&gt;&#xA;&lt;li&gt;rstan and shinystan are now optional&lt;/li&gt;&#xA;&lt;li&gt;Fix problems with multiple clusters in the posterior predictive function&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;To get the latest version of the bpcs package, install it from Github:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Writing R packages With Stan</title>
      <link>http://localhost:1313/post/2021/packages-with-stan/</link>
      <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2021/packages-with-stan/</guid>
      <description>&lt;p&gt;Now, I have been developing the &lt;a href=&#34;https://github.com/davidissamattos/bpcs&#34;&gt;bpcs&lt;/a&gt; package for the last 4 months I thought of sharing a bit my experience with developing a R package with Stan.&lt;/p&gt;&#xA;&lt;h2 id=&#34;rstan--rstantools&#34;&gt;rstan + rstantools&lt;/h2&gt;&#xA;&lt;p&gt;My first experience was with &lt;code&gt;rstan&lt;/code&gt; + &lt;code&gt;rstantools&lt;/code&gt;. Creating a skeleton package based on &lt;code&gt;rstantools&lt;/code&gt; is really fast and straightforward.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;During installation time, the Stan model is compiled and ready to be called. This creates a longer time in development if you are constantly changing the Stan model&#xA;&lt;ul&gt;&#xA;&lt;li&gt;My experience is that it is best to have an almost-ready model before starting to iterate with the package. Alternatively, have a script where you can test the model without the need to install. The installation process to compile the model takes longer than just using rstan.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Avoid having many models or you will be spending 20min in installation&lt;/li&gt;&#xA;&lt;li&gt;This can create problems if you are submitting to CRAN&lt;/li&gt;&#xA;&lt;li&gt;This can also create problems if you are using Github actions (since they limited time to run the CI)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;It is not always that changes in the model result in a re-compilation in Rstudio with devtools. Through some trial and error I found that to force recompilation you need:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;pkgbuild::clean_dll()&lt;/code&gt; to clean the source files. This will force recompile &amp;ndash;&amp;gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;devtools::document()&lt;/code&gt;. This will update the package and recompile the model&lt;/li&gt;&#xA;&lt;li&gt;Restart the r session to make the model reload in the memory&lt;/li&gt;&#xA;&lt;li&gt;Run&lt;code&gt;devtools::load_all()&lt;/code&gt; again. Now you are ready to test your recompiled model&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I found problems when using the &lt;code&gt;rstan::gqs&lt;/code&gt; function. To give some context, I fitted my model with &lt;code&gt;rstan::sample&lt;/code&gt; (no problems here) and then I used &lt;code&gt;rstan::gqs&lt;/code&gt; in a &lt;code&gt;predict&lt;/code&gt; S3 function with the parameters fitted from the model.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;My problem here is that (I think) there are/were some bugs in the generated quantities in Stan.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Estimated parameters could not be optional since they need to be present, so I needed to have transformed parameters to make sure all parameters were present&lt;/li&gt;&#xA;&lt;li&gt;The transformed parameters did not play nice with the generated quantities and the recommended approach is to have the transformed parameters inside the generated quantities. This increases copy and paste in the model&lt;/li&gt;&#xA;&lt;li&gt;With transformed parameters I was doing a lot of subsets (e.g. a parameter was a vector, the transformed parameters was a real and I was assigning to the real variable only the first item of the transformed parameter). Apparently, this creates a problem in CRAN with ubsan-clang where the Stan code is not properly compiled in clang and leads to memory errors in macOS. There are no tools to investigate this and there is a lot of trial and errors with a very specific setup. This lead me to change to &lt;code&gt;cmdstanr&lt;/code&gt; in the package development.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;cmdstanr&#34;&gt;cmdstanr&lt;/h2&gt;&#xA;&lt;p&gt;For version 1.2.0, I decided to change to &lt;code&gt;cmdstanr&lt;/code&gt; instead of the &lt;code&gt;rstan&lt;/code&gt; + &lt;code&gt;rstantools&lt;/code&gt; combo. My decision was based on:&lt;/p&gt;</description>
    </item>
    <item>
      <title>SE Seminar 2021 - “Bayesian Bradley-Terry models: from primates to machine learning”</title>
      <link>http://localhost:1313/post/2021/se-seminar-2021/</link>
      <pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2021/se-seminar-2021/</guid>
      <description>&lt;p&gt;This Feb 5th, I will present some of my research around Bradley-Terry models in the SE Seminar at Chalmers.&lt;/p&gt;&#xA;&lt;p&gt;My goal is to show a the generality of the Bayesian BT model and that it can be used for both behavior research as well as software engineering.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Bayesian Bradley-Terry models: from primates to machine learning&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;This presentation has a little something for everyone: it has SE, ML, Bayesian statistics, survey, R, math, gorillas using technology and football. We will start discussing paired-comparison data with food preferences in gorillas using touchscreen displays. From there we will move to an introduction of the Bradley-Terry model and why you should care about it in SE. We discuss two SE applications: surveys and benchmark experiments. For benchmark experiments we discuss how to rank automated labeling techniques with the Bradley-Terry model with random effects. Finally, we conclude this presentation showing an application of the Davidson model with data from the Brazilian national football league. Of course everything is Bayesian and done in R with the bpcs package (that we created). We make all code available in a R notebook.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bayesian Paired-Comparison with the bpcs Package</title>
      <link>http://localhost:1313/post/2021/bpcs-paper/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2021/bpcs-paper/</guid>
      <description>&lt;p&gt;Yesterday, we submitted the paper: Mattos, D. I. and Ramos, E. M. S. &amp;ldquo;Bayesian Paired-Comparison with the bpcs Package&amp;rdquo; arxiv:2101.11227&lt;/p&gt;&#xA;&lt;p&gt;This paper discusses all the statistical models implemented in the bpcs package and makes three deep reanalyses of existing behavior research. See below the abstract.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&amp;ldquo;This article introduces the bpcs R package (Bayesian Paired Comparison in Stan) and the statistical models implemented in the package. The goal of this package is to facilitate the use of Bayesian models for paired comparison data in behavioral research. Historically, studies on preferences have relied on Likert scale assessments and the frequentist approach to analyze the data. As an alternative, this article proposes the use of Bayesian models for forced choices assessments. The advantages of forced-choice assessments are that they minimize common bias that Likert scales are susceptible to, they can increase criterion validity, control for faking responses, and are quite useful to assess preferences in studies with children and non-humans primates. Bayesian data analyses are less sensitive to optional stopping, have better control of type I error, have stronger evidence towards the null hypothesis, allows propagation of uncertainties, includes prior information, and perform well when handling models with many parameters and latent variables. The bpcs package provides a consistent interface for R users and several functions to evaluate the posterior distribution of all parameters, to estimate the posterior distribution of any contest between items, and to obtain the posterior distribution of the ranks. Three reanalyses of recent studies that used the frequentist Bradley-Terry model are presented. These reanalyses are conducted with the Bayesian models of the bpcs package and all the code used to fit the models, generate the figures and the tables are available in the online appendix.&amp;rdquo;&lt;/p&gt;</description>
    </item>
    <item>
      <title>bpcs - release v.1.1</title>
      <link>http://localhost:1313/post/2021/bpcs-release-1.1.0/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2021/bpcs-release-1.1.0/</guid>
      <description>&lt;p&gt;A new release of the bpcs package is available in Github. This release introduces new models and correct some bugs. This release will be submitted to CRAN (not there yet) and the on-going paper we are writing is based on this release.&lt;/p&gt;&#xA;&lt;p&gt;See below the release notes:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Possibility to add up to 3 intercept random effects (hopefully you will never need more than that)&lt;/li&gt;&#xA;&lt;li&gt;Model for subject predictors&lt;/li&gt;&#xA;&lt;li&gt;Make predictions of submodels with the model_type option&lt;/li&gt;&#xA;&lt;li&gt;Some small bug fixes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Unfortunately, we didn&amp;rsquo;t have time to add a function to obtain the posterior distribution of the parameters without accessing the stanfit directly. But I think the other features are worth to update!&lt;/p&gt;</description>
    </item>
    <item>
      <title>The GYSS started this week</title>
      <link>http://localhost:1313/post/2021/gyss-started/</link>
      <pubDate>Tue, 12 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2021/gyss-started/</guid>
      <description>&lt;p&gt;The Global Youth Scientists Summit (GYSS) conference started this week. The GYSS is a gathering of PhD students and post-docs of al over the world to discuss and hear from top scientists and leaders. This year it has 21 speakers that won the Nobel prize, the Fields medal or the Turing award.&lt;/p&gt;&#xA;&lt;p&gt;I had the privelige of being select as one of the 5 PhD/post docs from Chalmers to participate and I will be having a small-session of question and answers discussion with Sir Timothy Gowers (Fields medal 98).&lt;/p&gt;</description>
    </item>
    <item>
      <title>bpcs - release v.1.0.1</title>
      <link>http://localhost:1313/post/2020/bpcs-release-1.0.1/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2020/bpcs-release-1.0.1/</guid>
      <description>&lt;p&gt;This is a minor release to streamline the usage of the bpcs package, correct a few bugs and add publication-ready functions for tables and figures&lt;/p&gt;&#xA;&lt;p&gt;See below the release notes:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;removed ties_pred from models that do not have ties&lt;/li&gt;&#xA;&lt;li&gt;fixed predict for models with ties, so we return a vector y_pred with 0, 1, 2 and not separate as now&lt;/li&gt;&#xA;&lt;li&gt;removed posterior distributions from the get_rank_of_players and get_probabilities. Now we have new functions to obtain the data frame or the posterior distributions separately. The posterior is now returned as matrix&lt;/li&gt;&#xA;&lt;li&gt;Probabilities table is now optional in the summary function&lt;/li&gt;&#xA;&lt;li&gt;New functions to get the probabilities for specific data &lt;code&gt;get_probabilities_newdata_df&lt;/code&gt; and &lt;code&gt;get_probabilities_newdata_posterior&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Publication ready functions for&#xA;&lt;ul&gt;&#xA;&lt;li&gt;plots: &lt;code&gt;get_parameters_plot&lt;/code&gt; function and a thin S3 plot wrapper for the same function. Plots are default to APA.&lt;/li&gt;&#xA;&lt;li&gt;tables: Functions for publication tables: &lt;code&gt;get_parameter_table&lt;/code&gt;, &lt;code&gt;get_probabilities_table&lt;/code&gt; and &lt;code&gt;get_rank_of_players_table&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;get_hpdi_parameters&lt;/code&gt;  became &lt;code&gt;get_parameters&lt;/code&gt; and the user specify if credible intervals or hpdi&lt;/li&gt;&#xA;&lt;li&gt;Added ties to &lt;code&gt;expand_aggregated_data&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;We can get now both credible and HPD intervals in &lt;code&gt;get_parameters&lt;/code&gt;. n_eff and Rhat are also now possible to add and remove from this df&lt;/li&gt;&#xA;&lt;li&gt;Added functions to save and load bpc models&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;To get the latest version of the bpcs package, install it from Github:&lt;/p&gt;</description>
    </item>
    <item>
      <title>The bpcs package is now on CRAN</title>
      <link>http://localhost:1313/post/2020/bpcs-cran/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2020/bpcs-cran/</guid>
      <description>&lt;p&gt;After some months of work the bpcs package is at version v1.0.0 and is available on CRAN (&lt;a href=&#34;https://CRAN.R-project.org/package=bpcs)&#34;&gt;https://CRAN.R-project.org/package=bpcs)&lt;/a&gt;. Now we can easily run Bayesian inference on Bradley-Terry models (including many extensions).&lt;/p&gt;&#xA;&lt;p&gt;See below the description of the package&lt;/p&gt;&#xA;&lt;p&gt;Models for the analysis of paired comparison data using Stan. The models include Bayesian versions of the Bradley-Terry model, including random effects (1 level), generalized model for predictors, order effect (home advantage) and the variations for the Davidson (1970) model to handle ties. Additionally, we provide a number of functions to facilitate inference and obtaining results with these models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>New website</title>
      <link>http://localhost:1313/post/2020/hello-world/</link>
      <pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2020/hello-world/</guid>
      <description>&lt;p&gt;As I am finishing now my PhD, I decided it was time to have a personal website with a section to create some small personal blog posts, update my cv etc..&lt;/p&gt;&#xA;&lt;p&gt;I end up going for the following technologies:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Static website based on &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Hugo is simple to use, the pages are written in markdown, it is fast and easy to deploy.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Hugo theme: &lt;a href=&#34;https://themes.gohugo.io/anatole/&#34;&gt;Anatole&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A clean and easy to use theme.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Netlify for hosting&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Good support for Hugo with CD, so it is just commiting and pushing to Github and Netlify updates and builds your website automatically.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
